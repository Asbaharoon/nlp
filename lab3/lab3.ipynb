{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, LSTM, Dense\n",
    "from keras.models import Model, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_gpu(gpu_id):\n",
    "    import os\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple gpus\n",
    "use_gpu(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'cmn.txt'\n",
    "ENG_EMBEDDING = 'glove.840B.300d.txt'\n",
    "EMBEDDING_DIM = 300\n",
    "LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "SAVED_MODEL = 'nmt.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_word_embedding():\n",
    "    import os\n",
    "    if not os.path.exists(ENG_EMBEDDING):\n",
    "        if not os.path.exists('glove.840B.300d.zip'):\n",
    "            os.system('wget http://nlp.stanford.edu/data/glove.840B.300d.zip')\n",
    "        os.system('unzip cmn-eng.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    import os\n",
    "    if not os.path.exists(DATA):\n",
    "        if not os.path.exists('cmn-eng.zip'):\n",
    "            os.system('wget http://www.manythings.org/anki/cmn-eng.zip')\n",
    "        os.system('unzip cmn-eng.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embedding(filename, dimension):\n",
    "    embeddings_index = {}\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = ''.join(values[:-dimension])\n",
    "            embeddings_index[word] = np.asarray(values[-dimension:], dtype='float32')\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = [line.strip().split('\\t') for line in f]\n",
    "        return zip(*lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(lines, tokenizer, append_start=False, append_end=False):\n",
    "    # default word index (stopping token is 0)\n",
    "    word_index = {\n",
    "        'unk': 1,\n",
    "        '<S>': 2,\n",
    "    }\n",
    "    index = 3\n",
    "    # each line to a sequence of index\n",
    "    seq = []\n",
    "    for line in lines:\n",
    "        preprocessed_line = tokenizer(line)\n",
    "        if append_start:\n",
    "            preprocessed_line = ['<S>'] + preprocessed_line\n",
    "        if append_end:\n",
    "            preprocessed_line = preprocessed_line + ['<S>']\n",
    "        # register in word_index\n",
    "        for word in preprocessed_line:\n",
    "            if word not in word_index:\n",
    "                word_index[word] = index\n",
    "                index += 1\n",
    "        seq.append([word_index[word] for word in preprocessed_line])\n",
    "    # pad sequence with 0 (stopping token)\n",
    "    data = pad_sequences(seq, padding='post')\n",
    "    return data, word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_word_embedding()\n",
    "# download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = load_word_embedding(ENG_EMBEDDING, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lines, ch_lines = load_dataset(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data, en_word_index = get_word_index(en_lines, nltk.word_tokenize, append_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng embedding\n",
    "zeros = np.zeros(EMBEDDING_DIM)\n",
    "embedding_matrix = np.zeros((len(en_word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in en_word_index.items():\n",
    "    embedding_matrix[i] = embeddings_index.get(word, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_1 = Embedding(*embedding_matrix.shape,\n",
    "                        weights=[embedding_matrix],\n",
    "                        mask_zero=True,\n",
    "                        trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chengscott/venv-nlp/lib/python3.6/site-packages/jieba/__init__.py\", line 152, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmpe5fm0g54' -> '/tmp/jieba.cache'\n",
      "Loading model cost 1.901 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "ch_data, ch_word_index = get_word_index(ch_lines, jieba.lcut, append_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data, _ = get_word_index(ch_lines, jieba.lcut, append_end=True)\n",
    "target_data = target_data[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch embedding\n",
    "embedding_matrix = np.random.random(size=(len(ch_word_index) + 1, EMBEDDING_DIM))\n",
    "embedding_matrix[0] = np.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2 = Embedding(*embedding_matrix.shape,\n",
    "                        weights=[embedding_matrix],\n",
    "                        mask_zero=True,\n",
    "                        trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMT Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_en_seq_len = en_data.shape[0]\n",
    "max_ch_seq_len = ch_data.shape[0]\n",
    "num_decoder_tokens = len(ch_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_seq_inputs = Input(shape=(None,))\n",
    "encoder_inputs = embedding_1(en_seq_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_seq_inputs = Input(shape=(None,))\n",
    "decoder_inputs = embedding_2(ch_seq_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "dense_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([en_seq_inputs, ch_seq_inputs], dense_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2067000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    4095300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 570368      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  570368      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 13650)  3508050     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,811,086\n",
      "Trainable params: 8,744,086\n",
      "Non-trainable params: 2,067,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16235 samples, validate on 4059 samples\n",
      "Epoch 1/100\n",
      "16235/16235 [==============================] - 58s 4ms/step - loss: 1.5264 - val_loss: nan\n",
      "Epoch 2/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 1.4661 - val_loss: nan\n",
      "Epoch 3/100\n",
      "16235/16235 [==============================] - 45s 3ms/step - loss: 1.4181 - val_loss: nan\n",
      "Epoch 4/100\n",
      "16235/16235 [==============================] - 47s 3ms/step - loss: 1.3746 - val_loss: nan\n",
      "Epoch 5/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 1.3352 - val_loss: nan\n",
      "Epoch 6/100\n",
      "16235/16235 [==============================] - 42s 3ms/step - loss: 1.1758 - val_loss: nan\n",
      "Epoch 10/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 1.1389 - val_loss: nan\n",
      "Epoch 11/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 1.0998 - val_loss: nan\n",
      "Epoch 12/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 1.0664 - val_loss: nan\n",
      "Epoch 13/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 1.0285 - val_loss: nan\n",
      "Epoch 14/100\n",
      "16235/16235 [==============================] - 42s 3ms/step - loss: 0.9979 - val_loss: nan\n",
      "Epoch 15/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.9660 - val_loss: nan\n",
      "Epoch 16/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.9345 - val_loss: nan\n",
      "Epoch 17/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.9001 - val_loss: nan\n",
      "Epoch 18/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.8689 - val_loss: nan\n",
      "Epoch 19/100\n",
      "16235/16235 [==============================] - 42s 3ms/step - loss: 0.8429 - val_loss: nan\n",
      "Epoch 20/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.8095 - val_loss: nan\n",
      "Epoch 21/100\n",
      "  960/16235 [>.............................] - ETA: 42s - loss: 0.7674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.6533 - val_loss: nan\n",
      "Epoch 27/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.6285 - val_loss: nan\n",
      "Epoch 28/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6057 - val_loss: nan\n",
      "Epoch 29/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5845 - val_loss: nan\n",
      "Epoch 30/100\n",
      "16235/16235 [==============================] - 41s 3ms/step - loss: 0.5604 - val_loss: nan\n",
      "Epoch 31/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5389 - val_loss: nan\n",
      "Epoch 32/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5218 - val_loss: nan\n",
      "Epoch 33/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5018 - val_loss: nan\n",
      "Epoch 34/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4787 - val_loss: nan\n",
      "Epoch 35/100\n",
      "16235/16235 [==============================] - 43s 3ms/step - loss: 0.4630 - val_loss: nan\n",
      "Epoch 36/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.4449 - val_loss: nan\n",
      "Epoch 37/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4262 - val_loss: nan\n",
      "Epoch 38/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4095 - val_loss: nan\n",
      "Epoch 39/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3944 - val_loss: nan\n",
      "Epoch 40/100\n",
      "16235/16235 [==============================] - 46s 3ms/step - loss: 0.3794 - val_loss: nan\n",
      "Epoch 41/100\n",
      "16235/16235 [==============================] - 47s 3ms/step - loss: 0.3643 - val_loss: nan\n",
      "Epoch 42/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3453 - val_loss: nan\n",
      "Epoch 43/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3327 - val_loss: nan\n",
      "Epoch 44/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3207 - val_loss: nan\n",
      "Epoch 45/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3066 - val_loss: nan\n",
      "Epoch 46/100\n",
      "16235/16235 [==============================] - 41s 3ms/step - loss: 0.2948 - val_loss: nan\n",
      "Epoch 47/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2829 - val_loss: nan\n",
      "Epoch 48/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2716 - val_loss: nan\n",
      "Epoch 49/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.2598 - val_loss: nan\n",
      "Epoch 50/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2490 - val_loss: nan\n",
      "Epoch 51/100\n",
      "16235/16235 [==============================] - 41s 3ms/step - loss: 0.2396 - val_loss: nan\n",
      "Epoch 52/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2291 - val_loss: nan\n",
      "Epoch 53/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2197 - val_loss: nan\n",
      "Epoch 54/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2124 - val_loss: nan\n",
      "Epoch 55/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.2031 - val_loss: nan\n",
      "Epoch 56/100\n",
      "16235/16235 [==============================] - 43s 3ms/step - loss: 0.1951 - val_loss: nan\n",
      "Epoch 57/100\n",
      "16235/16235 [==============================] - 45s 3ms/step - loss: 0.1889 - val_loss: nan\n",
      "Epoch 58/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.1808 - val_loss: nan\n",
      "Epoch 59/100\n",
      "16235/16235 [==============================] - 47s 3ms/step - loss: 0.1741 - val_loss: nan\n",
      "Epoch 60/100\n",
      "16235/16235 [==============================] - 47s 3ms/step - loss: 0.1668 - val_loss: nan\n",
      "Epoch 61/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.1606 - val_loss: nan\n",
      "Epoch 62/100\n",
      "16235/16235 [==============================] - 42s 3ms/step - loss: 0.1543 - val_loss: nan\n",
      "Epoch 63/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1490 - val_loss: nan\n",
      "Epoch 64/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1436 - val_loss: nan\n",
      "Epoch 65/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1387 - val_loss: nan\n",
      "Epoch 66/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.1343 - val_loss: nan\n",
      "Epoch 67/100\n",
      "16235/16235 [==============================] - 42s 3ms/step - loss: 0.1289 - val_loss: nan\n",
      "Epoch 68/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.1259 - val_loss: nan\n",
      "Epoch 69/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.1209 - val_loss: nan\n",
      "Epoch 70/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1169 - val_loss: nan\n",
      "Epoch 71/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1134 - val_loss: nan\n",
      "Epoch 72/100\n",
      "16235/16235 [==============================] - 45s 3ms/step - loss: 0.1104 - val_loss: nan\n",
      "Epoch 73/100\n",
      "16235/16235 [==============================] - 47s 3ms/step - loss: 0.1074 - val_loss: nan\n",
      "Epoch 74/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.1028 - val_loss: nan\n",
      "Epoch 75/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.1006 - val_loss: nan\n",
      "Epoch 76/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.0979 - val_loss: nan\n",
      "Epoch 77/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.0957 - val_loss: nan\n",
      "Epoch 78/100\n",
      "16235/16235 [==============================] - 43s 3ms/step - loss: 0.0925 - val_loss: nan\n",
      "Epoch 79/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.0900 - val_loss: nan\n",
      "Epoch 80/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.0876 - val_loss: nan\n",
      "Epoch 81/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.0855 - val_loss: nan\n",
      "Epoch 82/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.0846 - val_loss: nan\n",
      "Epoch 83/100\n",
      "16235/16235 [==============================] - 44s 3ms/step - loss: 0.0818 - val_loss: nan\n",
      "Epoch 84/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.0748 - val_loss: nan\n",
      "Epoch 88/100\n",
      "16235/16235 [==============================] - 41s 3ms/step - loss: 0.0731 - val_loss: nan\n",
      "Epoch 89/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.0721 - val_loss: nan\n",
      "Epoch 90/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.0708 - val_loss: nan\n",
      "Epoch 91/100\n",
      "16235/16235 [==============================] - 46s 3ms/step - loss: 0.0697 - val_loss: nan\n",
      "Epoch 92/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.0681 - val_loss: nan\n",
      "Epoch 93/100\n",
      "16235/16235 [==============================] - 46s 3ms/step - loss: 0.0666 - val_loss: nan\n",
      "Epoch 94/100\n",
      "16235/16235 [==============================] - 44s 3ms/step - loss: 0.0653 - val_loss: nan\n",
      "Epoch 95/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.0639 - val_loss: nan\n",
      "Epoch 96/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.0629 - val_loss: nan\n",
      "Epoch 97/100\n",
      "16235/16235 [==============================] - 48s 3ms/step - loss: 0.0618 - val_loss: nan\n",
      "Epoch 98/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.0609 - val_loss: nan\n",
      "Epoch 99/100\n",
      "16235/16235 [==============================] - 41s 3ms/step - loss: 0.0598 - val_loss: nan\n",
      "Epoch 100/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.0592 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76c27cde80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')\n",
    "model.fit([en_data, ch_data], target_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengscott/venv-nlp/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save(SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMT Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_seq_inputs = model.input[0]\n",
    "encoder_inputs = model.layers[2](en_seq_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_seq_inputs = model.input[1]\n",
    "decoder_inputs = model.layers[3](ch_seq_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.layers[4]\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(en_seq_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 300)         2067000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 256), (None, 256) 570368    \n",
      "=================================================================\n",
      "Total params: 2,637,368\n",
      "Trainable params: 570,368\n",
      "Non-trainable params: 2,067,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='input_h')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='input_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = model.layers[6]\n",
    "dense_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [ch_seq_inputs] + decoder_states_inputs,\n",
    "    [dense_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    4095300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_h (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_c (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  570368      embedding_2[1][0]                \n",
      "                                                                 input_h[0][0]                    \n",
      "                                                                 input_c[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 13650)  3508050     lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,173,718\n",
      "Trainable params: 8,173,718\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_index_word = {c: i for i, c in ch_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmt_inference(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # <s> starting word\n",
    "    target_seq = np.array([[2.]])\n",
    "    decoded_sentence = []\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        output_index = np.argmax(output_tokens[0, -1, :])\n",
    "        word = ch_index_word[output_index]\n",
    "        decoded_sentence.append(word)\n",
    "        if word == '<S>':\n",
    "            break\n",
    "        # update states\n",
    "        target_seq = np.array([[output_index]])\n",
    "        states_value = [h, c]\n",
    "    return ''.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence:\tHe is afraid of snakes.\n",
      "Decoded sentence:\t他害怕蛇。<S>\n",
      "-\n",
      "Input sentence:\tI miss you so much.\n",
      "Decoded sentence:\t好想見到你<S>\n",
      "-\n",
      "Input sentence:\tWe're going by train.\n",
      "Decoded sentence:\t我们要乘火车去。<S>\n",
      "-\n",
      "Input sentence:\tThe sky is clear.\n",
      "Decoded sentence:\t天空很晴朗。<S>\n",
      "-\n",
      "Input sentence:\tWearing a suit, he stood out.\n",
      "Decoded sentence:\t他穿著西裝站了出來。<S>\n",
      "-\n",
      "Input sentence:\tShe made a serious mistake.\n",
      "Decoded sentence:\t她犯了一個嚴重的錯誤。<S>\n",
      "-\n",
      "Input sentence:\tHave you eaten dinner?\n",
      "Decoded sentence:\t你吃晚飯了嗎？<S>\n",
      "-\n",
      "Input sentence:\tWhat do you want to be?\n",
      "Decoded sentence:\t你想成为什么？<S>\n",
      "-\n",
      "Input sentence:\tTom is going to help us.\n",
      "Decoded sentence:\t汤姆要帮助我们。<S>\n",
      "-\n",
      "Input sentence:\tHe's lazy.\n",
      "Decoded sentence:\t他很懒。<S>\n"
     ]
    }
   ],
   "source": [
    "line_no = [4077, 2122, 3335, 1464, 8956, 7168, 3490, 4495, 5100, 119]\n",
    "line_no = [n - 1 for n in line_no]\n",
    "for n in line_no:\n",
    "    input_seq = en_data[n: n + 1]\n",
    "    decoded_sentence = nmt_inference(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', en_lines[n], sep='\\t')\n",
    "    # print('Train sentence:', ch_lines[n], sep='\\t')\n",
    "    print('Decoded sentence:', decoded_sentence, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
